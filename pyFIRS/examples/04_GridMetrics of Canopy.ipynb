{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import dask\n",
    "from dask.distributed import Client, progress, LocalCluster\n",
    "from pyFIRS.wrappers import lastools, fusion\n",
    "from pyFIRS.utils import clean_dir, clip_tile_from_shp, convert_project, PipelineError, fname, inspect_failures, processing_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch a parallel computing cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster=LocalCluster(scheduler_port=7001, diagnostics_port=7002)\n",
    "c = Client(cluster)\n",
    "num_cores = len(c.ncores()) # identify how many workers we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you should also be able to view an interactive dashboard on port 7002. If you're executing this on a remote server, you'll need to set up port forward so you can view the dashboard on your local machine's browser. Once you've done that, or if you're processing on your own machine, you can view the dashboard at [http://localhost:7002/status](http://localhost:7002/status)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "las = lastools.useLAStools('/storage/lidar/LAStools/bin')\n",
    "fus = fusion.useFUSION('/storage/lidar/FUSION/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the imported lidar data is currently stored\n",
    "WORKDIR = os.path.abspath('/storage/lidar/hoh-river_2012/')\n",
    "\n",
    "# define data handling directories\n",
    "INTERIM = os.path.join(WORKDIR, 'interim')\n",
    "PROCESSED = os.path.join(WORKDIR, 'processed')\n",
    "\n",
    "# the coordinate reference system we'll be working with\n",
    "TARGET_EPSG = 6339 # utm 10N, NAD83_2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_error(tile_id, process, error_msg):\n",
    "    logfile = os.path.join(INTERIM, 'failed', tile_id + '.txt')\n",
    "    os.makedirs(os.path.dirname(logfile), exist_ok=True)\n",
    "    \n",
    "    with open(logfile, '+w') as f:\n",
    "        f.write('{} | {}: {}'.format(tile_id, process, error_msg))\n",
    "    \n",
    "    return\n",
    "\n",
    "def has_error(tile_id):\n",
    "    errors = glob.glob(os.path.join(INTERIM, 'failed', '*.txt'))\n",
    "    tiles_with_errors = [os.path.basename(error).split('.')[0] for error in errors]\n",
    "    if tile_id in tiles_with_errors:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strata_cols_to_grid = {'Elev strata (below 0.15) return proportion':'strat0_return-proportion',\n",
    "                       'Elev strata (0.15 to 1.37) return proportion':'strat1_return-proportion',\n",
    "                       'Elev strata (5.00 to 10.00) return proportion':'strat2_return-proportion',\n",
    "                       'Elev strata (10.00 to 20.00) return proportion':'strat3_return-proportion',\n",
    "                       'Elev strata (20.00 to 30.00) return proportion':'strat4_return-proportion',\n",
    "                       'Elev strata (above 30.00) return proportion':'strat5_return-proportion',\n",
    "                       'Int strata (below 0.15) median':'strat0_intensity-median',\n",
    "                       'Int strata (0.15 to 1.37) median':'strat1_intensity-median',\n",
    "                       'Int strata (1.37 to 5.00) median':'strat2_intensity-median',\n",
    "                       'Int strata (5.00 to 10.00) median':'strat3_intensity-median',\n",
    "                       'Int strata (10.00 to 20.00) median':'strat4_intensity-median',\n",
    "                       'Int strata (above 30.00) median':'strat5_intensity-median'\n",
    "                      }\n",
    "\n",
    "elevation_cols_to_grid = {'Elev P05':'height_05-percentile',\n",
    "                          'Elev P25':'height_25-percentile',\n",
    "                          'Elev P50':'height_50-percentile',\n",
    "                          'Elev P75':'height_75-percentile',\n",
    "                          'Elev P95':'height_95_percentile',\n",
    "                          'Elev maximum':'height_max',\n",
    "                          'Percentage all returns above 1.37':'cover' # just added back in\n",
    "                         }\n",
    "\n",
    "topo_cols_to_grid = {'Elevation':'elevation',\n",
    "                     'Slope (degrees)':'slope',\n",
    "                     'Aspect (degrees azimuth)':'aspect', # not showing up\n",
    "                     'Profile curvature * 100':'profile_curvature',\n",
    "                     'Plan curvature * 100':'plan_curvature',\n",
    "                     'Solar Radiation Index':'solar_radiation_index',\n",
    "                     'Overall Curvature':'overall_curvature' # not showing up\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push our working directories and wrapper classes to the workers on the cluster as well\n",
    "c.scatter([INTERIM, PROCESSED, las, fus, \n",
    "           TARGET_EPSG, num_cores, has_error, log_error,\n",
    "           strata_cols_to_grid, topo_cols_to_grid, elevation_cols_to_grid], \n",
    "          broadcast=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Canopy GridMetrics\n",
    "Calculate forest attributes using the FUSION `gridmetrics` tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def make_gridmetrics(tile_id):\n",
    "    infile = os.path.join(PROCESSED, 'points', tile_id + '.laz')\n",
    "    groundfile = os.path.join(INTERIM, 'dtm_ground_tiles', tile_id + '.dtm')\n",
    "    odir = os.path.join(PROCESSED, 'rasters', 'gridmetrics')\n",
    "    outfile = os.path.join(odir, tile_id + '.csv')\n",
    "    \n",
    "    # get the latitude of the tile centroid\n",
    "    gdf = gpd.read_file(os.path.join(INTERIM, 'tile_boundaries', tile_id+'.shp'))\n",
    "    latlon = gdf.exterior.centroid.to_crs({'init':'EPSG:4326'})\n",
    "    latitude = latlon.geometry.y.values[0]\n",
    "    \n",
    "    # get the coordinates of the lower left corner of the tile\n",
    "    tile_parts = tile_id.split('_')\n",
    "    if len(tile_parts) == 2:\n",
    "        grid_x, grid_y = [int(coord) for coord in tile_parts]\n",
    "        tile_length = 1000 # assumed tile width if not explicit in tile_id\n",
    "    elif len(tile_parts) == 3:\n",
    "        grid_x, grid_y, tile_length = [int(coord) for coord in tile_parts]\n",
    "    \n",
    "    if not os.path.exists(outfile):\n",
    "        if not has_error(tile_id):\n",
    "            try:\n",
    "                proc = fus.gridmetrics(groundfile=groundfile,\n",
    "                                       heightbreak=1.37, # breast height, in meters\n",
    "                                       cellsize=10, # in units of lidar data\n",
    "                                       grid=(grid_x, grid_y, tile_length, tile_length),\n",
    "                                       buffer=30,\n",
    "                                       outlier=(-1,110),\n",
    "                                       outputfile=outfile,\n",
    "                                       datafiles=infile,\n",
    "                                       strata=(0.15, 1.37, 5.0, 10.0, 20.0, 30.0),\n",
    "                                       intstrata=(0.15, 1.37, 5.0, 10.0, 20.0, 30.0),\n",
    "                                       las_class=(0,1,2,3,4,5),\n",
    "                                       topo=(10,latitude),\n",
    "                                       odir=odir) # will make sure output directory is created if doesn't already exist\n",
    "                \n",
    "            except PipelineError as e:\n",
    "                        log_error(tile_id, 'make_gridmetrics', e.message)\n",
    "    else: # output file already exists\n",
    "        pass\n",
    "                \n",
    "    return tile_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def make_gridsurfacestats(tile_id):\n",
    "    infile = os.path.join(INTERIM, 'chm_tiles', tile_id + '.dtm')\n",
    "    odir = os.path.join(INTERIM, 'gridsurface')\n",
    "    outfile = os.path.join(odir, tile_id + '.dtm')\n",
    "    \n",
    "    tile_parts = tile_id.split('_')\n",
    "    if len(tile_parts) == 2:\n",
    "        grid_x, grid_y = [int(coord) for coord in tile_parts]\n",
    "        tile_length = 1000 # assumed tile width if not explicit in tile_id\n",
    "    elif len(tile_parts) == 3:\n",
    "        grid_x, grid_y, tile_length = [int(coord) for coord in tile_parts]\n",
    "    \n",
    "    test_output = os.path.join(odir, tile_id + '_max_height' + '.dtm')\n",
    "    if not os.path.exists(test_output):\n",
    "        if not has_error(tile_id):\n",
    "            try:\n",
    "                proc = fus.gridsurfacestats(inputfile=infile,\n",
    "                                            outputfile=outfile,\n",
    "                                            samplefactor=20,  # this 0.5m CHM, will produce 10*10m grid\n",
    "                                            grid=(grid_x, grid_y, 1000, 1000),\n",
    "                                            # samplefactors describes number of cells to use in grid\n",
    "                                            asc=True,\n",
    "                                            odir=odir) # will make sure output directory is created if doesn't already exist\n",
    "                \n",
    "            except PipelineError as e:\n",
    "                try:\n",
    "                    log_error(tile_id, 'make_gridsurfacestats', e.message)\n",
    "                except AttributeError:\n",
    "                    log_error(tile_id, 'make_gridsurfacestats', e)\n",
    "    else: # output file already exists\n",
    "        pass\n",
    "                \n",
    "    return tile_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv2grid(tile_id, csvfile, col_num, col_name):\n",
    "    outfile = os.path.join(INTERIM, 'gridmetrics', 'rasters', \n",
    "                           '{}_{}.asc'.format(tile_id, col_name))\n",
    "    odir = os.path.dirname(outfile)\n",
    "    \n",
    "    if not os.path.exists(outfile):\n",
    "        if not has_error(tile_id):\n",
    "            try:\n",
    "                proc = fus.csv2grid(inputfile=csvfile,\n",
    "                                    column=col_num,\n",
    "                                    outputfile=outfile,\n",
    "                                    odir=odir)\n",
    "                \n",
    "            except PipelineError as e:\n",
    "                        log_error(tile_id, 'csv2grid', e.message)\n",
    "    else: # output file already exists\n",
    "        pass\n",
    "                \n",
    "    return tile_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def batch_csv2grid(tile_id):\n",
    "    # read the csv containing strata data, identify the columns to extract\n",
    "    strata_data = os.path.join(PROCESSED, 'rasters', 'gridmetrics', tile_id + '_all_returns_strata_stats.csv')\n",
    "    \n",
    "    if not os.path.exists(strata_data):\n",
    "        log_error(tile_id, 'batch_csv2grid', '{} does not exist'.format(strata_data))\n",
    "        return tile_id\n",
    "    \n",
    "    with open(strata_data) as f:\n",
    "        header = f.readline().strip()\n",
    "        cols = header.split(',')\n",
    "        strata_columns = [{'col_num': cols.index(col)+1,  # FUSION wants indexing to start at 1\n",
    "                           'col_name': strata_cols_to_grid[col]}\n",
    "                          for col in cols if col in strata_cols_to_grid.keys()]\n",
    "\n",
    "    for col in strata_columns:\n",
    "        strata_proc = csv2grid(tile_id, strata_data, col['col_num'], col['col_name'])\n",
    "\n",
    "    \n",
    "    # read the csv containing topo data, identify the columns to extract\n",
    "    topo_data = os.path.join(PROCESSED, 'rasters', 'gridmetrics', tile_id + '_topo_metrics.csv')\n",
    "    with open(topo_data) as f:\n",
    "        header = f.readline().strip()\n",
    "        cols = header.split(',')\n",
    "        topo_columns = [{'col_num': cols.index(col)+1,\n",
    "                         'col_name': topo_cols_to_grid[col]}\n",
    "                        for col in cols if col in topo_cols_to_grid.keys()]\n",
    "\n",
    "    for col in topo_columns:\n",
    "        topo_proc = csv2grid(tile_id, topo_data, col['col_num'], col['col_name'])\n",
    "\n",
    "        \n",
    "    # read the csv containing elevation data, identify the columns to extract\n",
    "    elevation_data = os.path.join(PROCESSED, 'rasters', 'gridmetrics', tile_id + '_all_returns_elevation_stats.csv')    \n",
    "    with open(elevation_data) as f:\n",
    "        header = f.readline().strip()\n",
    "        cols = header.split(',')\n",
    "        elevation_columns = [{'col_num': cols.index(col)+1,\n",
    "                              'col_name': elevation_cols_to_grid[col]}\n",
    "                             for col in cols if col in elevation_cols_to_grid.keys()]\n",
    "\n",
    "    for col in elevation_columns:\n",
    "        elev_proc = csv2grid(tile_id, elevation_data, col['col_num'], col['col_name'])\n",
    "    \n",
    "    return tile_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def batch_asc2tif_gridmetrics(tile_id):\n",
    "    infiles = glob.glob(os.path.join(INTERIM, 'gridmetrics', 'rasters', '{}*.asc'.format(tile_id)))\n",
    "    ODIR = os.path.join(PROCESSED, 'rasters', 'gridmetrics')\n",
    "    \n",
    "    for infile in infiles:\n",
    "        filename = fname(infile)\n",
    "        outfile = os.path.join(ODIR, filename + '.tif')\n",
    "    \n",
    "        if not os.path.exists(outfile):\n",
    "            if not has_error(tile_id):\n",
    "                try:\n",
    "                    convert_project(infile, outfile, 'EPSG:{}'.format(TARGET_EPSG))\n",
    "                except Exception as e:\n",
    "                    log_error(tile_id, 'batch_asc2tif_gridmetrics', e.message)\n",
    "        else: # output file already exists\n",
    "            pass\n",
    "    \n",
    "    return tile_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def batch_asc2tif_gridsurface(tile_id):\n",
    "    infiles = glob.glob(os.path.join(INTERIM, 'gridsurface', '{}*.asc'.format(tile_id)))\n",
    "    ODIR = os.path.join(PROCESSED, 'rasters', 'gridsurface')\n",
    "    \n",
    "    for infile in infiles:\n",
    "        filename = fname(infile)\n",
    "        outfile = os.path.join(ODIR, filename + '.tif')\n",
    "    \n",
    "        if not os.path.exists(outfile):\n",
    "            if not has_error(tile_id):\n",
    "                try:\n",
    "                    convert_project(infile, outfile, 'EPSG:{}'.format(TARGET_EPSG))\n",
    "                except Exception as e:\n",
    "                    log_error(tile_id, 'batch_asc2tif_gridsurface', e.message)\n",
    "        else: # output file already exists\n",
    "            pass\n",
    "    \n",
    "    return tile_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def tile_done(tile_id, *args, **kwargs):\n",
    "    if type(tile_id) == list:\n",
    "        tile_id = tile_id[0]\n",
    "        \n",
    "    outfile = os.path.join(INTERIM, 'finished_gridmetrics', tile_id + '.txt')\n",
    "    os.makedirs(os.path.dirname(outfile), exist_ok=True)\n",
    "    \n",
    "    if not has_error(tile_id):\n",
    "        with open(outfile, '+a') as f:\n",
    "            f.write('{}'.format(tile_id))\n",
    "    \n",
    "    return tile_id\n",
    "\n",
    "@dask.delayed\n",
    "def tiles_done(*args, **kwargs):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_ids = set(fname(tile) for tile in\n",
    "                         glob.glob(os.path.join(PROCESSED, 'points', '*.laz'))\n",
    "                        )\n",
    "\n",
    "failed_tiles = set(fname(tile) for tile in \n",
    "                   glob.glob(os.path.join(INTERIM, 'failed', '*.txt'))\n",
    "                  )\n",
    "\n",
    "finished_tiles = set(fname(tile) for tile in \n",
    "                   glob.glob(os.path.join(INTERIM, 'finished_gridmetrics', '*.txt'))\n",
    "                  )\n",
    "\n",
    "tiles_to_process = list(tile_ids - failed_tiles - finished_tiles)\n",
    "\n",
    "print('Found {:,d} tiles to process'.format(len(tiles_to_process)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk = {}\n",
    "for tile in tiles_to_process:\n",
    "    dsk['make_gridsurfacestats-{}'.format(tile)]=(make_gridsurfacestats, tile)\n",
    "    dsk['make_gridmetrics-{}'.format(tile)]=(make_gridmetrics, tile)\n",
    "    \n",
    "    dsk['batch_asc2tif_gridsurface-{}'.format(tile)]=(batch_asc2tif_gridsurface, 'make_gridsurfacestats-{}'.format(tile))\n",
    "    dsk['batch_csv2grid-{}'.format(tile)]=(batch_csv2grid, 'make_gridmetrics-{}'.format(tile))\n",
    "    dsk['batch_asc2tif_gridmetrics-{}'.format(tile)]=(batch_asc2tif_gridmetrics, 'batch_csv2grid-{}'.format(tile))\n",
    "    \n",
    "    dsk['tile_done-{}'.format(tile)]=(tile_done, ['batch_asc2tif_gridsurface-{}'.format(tile),\n",
    "                                                  'batch_asc2tif_gridmetrics-{}'.format(tile)])\n",
    "    \n",
    "dsk['tiles_done'] = (tiles_done, ['tile_done-{}'.format(tile) for tile in tiles_to_process])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "example_tile_graph = c.get(dsk, 'tile_done-{}'.format(tiles_to_process[0]))\n",
    "example_tile_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_graph = c.get(dsk, 'tiles_done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_results = c.compute(tiles_graph) # this might take a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress(tiles_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c.cancel(tiles_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiles_results.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_summary(tile_ids, finished_tiles, tiles_to_process, os.path.join(INTERIM, 'finished_gridmetrics'), os.path.join(INTERIM, 'failed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_failures(os.path.join(INTERIM, 'failed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c.close()\n",
    "# cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyFIRS] *",
   "language": "python",
   "name": "conda-env-pyFIRS-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
