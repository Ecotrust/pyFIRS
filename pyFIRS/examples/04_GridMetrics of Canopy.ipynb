{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import dask\n",
    "from dask.distributed import Client, progress, LocalCluster\n",
    "from pyFIRS.wrappers import lastools, fusion\n",
    "from pyFIRS.utils import clean_dir, clip_tile_from_shp, convert_project, PipelineError, fname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch a parallel computing cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster=LocalCluster(scheduler_port=7001, diagnostics_port=7002)\n",
    "c = Client(cluster)\n",
    "num_cores = len(c.ncores()) # identify how many workers we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you should also be able to view an interactive dashboard on port 7002. If you're executing this on a remote server, you'll need to set up port forward so you can view the dashboard on your local machine's browser. Once you've done that, or if you're processing on your own machine, you can view the dashboard at [http://localhost:7002/status](http://localhost:7002/status)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "las = lastools.useLAStools('/storage/lidar/LAStools/bin')\n",
    "fus = fusion.useFUSION('/storage/lidar/FUSION/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the imported lidar data is currently stored\n",
    "workdir = os.path.abspath('/storage/lidar/olc_metro_2014/')\n",
    "\n",
    "# define data handling directories\n",
    "interim = os.path.join(workdir,'interim')\n",
    "processed = os.path.join(workdir,'processed')\n",
    "layers = os.path.join(interim, 'layers')\n",
    "\n",
    "# the coordinate reference system we'll be working with\n",
    "target_epsg = 26910 # utm 10 N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_error(tile_id, process, error_msg):\n",
    "    logfile = os.path.join(interim, 'failed', tile_id + '.txt')\n",
    "    os.makedirs(os.path.dirname(logfile), exist_ok=True)\n",
    "    \n",
    "    with open(logfile, '+w') as f:\n",
    "        f.write('{} | {}: {}'.format(tile_id, process, error_msg))\n",
    "    \n",
    "    return\n",
    "\n",
    "def has_error(tile_id):\n",
    "    errors = glob.glob(os.path.join(interim, 'failed', '*.txt'))\n",
    "    tiles_with_errors = [os.path.basename(error).split('.')[0] for error in errors]\n",
    "    if tile_id in tiles_with_errors:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strata_cols_to_grid = {'Elev strata (below 0.15) return proportion':'strat0_return-proportion',\n",
    "                       'Elev strata (0.15 to 1.37) return proportion':'strat1_return-proportion',\n",
    "                       'Elev strata (5.00 to 10.00) return proportion':'strat2_return-proportion',\n",
    "                       'Elev strata (10.00 to 20.00) return proportion':'strat3_return-proportion',\n",
    "                       'Elev strata (20.00 to 30.00) return proportion':'strat4_return-proportion',\n",
    "                       'Elev strata (above 30.00) return proportion':'strat5_return-proportion',\n",
    "                       'Int strata (below 0.15) median':'strat0_intensity-median',\n",
    "                       'Int strata (0.15 to 1.37) median':'strat1_intensity-median',\n",
    "                       'Int strata (1.37 to 5.00) median':'strat2_intensity-median',\n",
    "                       'Int strata (5.00 to 10.00) median':'strat3_intensity-median',\n",
    "                       'Int strata (10.00 to 20.00) median':'strat4_intensity-median',\n",
    "                       'Int strata (above 30.00) median':'strat5_intensity-median'\n",
    "                      }\n",
    "\n",
    "elevation_cols_to_grid = {'Elev P05':'height_05-percentile',\n",
    "                          'Elev P25':'height_25-percentile',\n",
    "                          'Elev P50':'height_50-percentile',\n",
    "                          'Elev P75':'height_75-percentile',\n",
    "                          'Elev P95':'height_95_percentile',\n",
    "                          'Elev maximum':'height_max'\n",
    "                         }\n",
    "\n",
    "topo_cols_to_grid = {'Elevation':'elevation',\n",
    "                     'Slope (degrees)':'slope',\n",
    "                     'Aspect (degrees, azimuth)':'aspect',\n",
    "                     'Profile curvature * 100':'profile_curvature',\n",
    "                     'Plan curvature * 100':'plan_curvature',\n",
    "                     'Solar Radiation Index':'solar_radiation_index',\n",
    "                     'Overall Curvature':'overall_curvature'\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push our working directories and wrapper classes to the workers on the cluster as well\n",
    "c.scatter([interim, processed, layers, las, fus, \n",
    "           target_epsg, num_cores, has_error, log_error,\n",
    "           strata_cols_to_grid, topo_cols_to_grid, elevation_cols_to_grid], \n",
    "          broadcast=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Canopy GridMetrics\n",
    "Calculate forest attributes using the FUSION `gridmetrics` tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def make_gridmetrics(tile_id):\n",
    "    infile = os.path.join(processed, 'points', tile_id + '.laz')\n",
    "    groundfile = os.path.join(interim, 'dtm_ground_tiles', tile_id + '.dtm')\n",
    "    odir = os.path.join(interim, 'gridmetrics')\n",
    "    outfile = os.path.join(odir, tile_id + '.csv')\n",
    "    \n",
    "    # get the latitude of the tile centroid\n",
    "    gdf = gpd.read_file(os.path.join(interim, 'tile_boundaries', tile_id+'.shp'))\n",
    "    latlon = gdf.exterior.centroid.to_crs({'init':'EPSG:4326'})\n",
    "    latitude = latlon.geometry.y.values[0]\n",
    "    \n",
    "    if not os.path.exists(outfile):\n",
    "        if not has_error(tile_id):\n",
    "            try:\n",
    "                proc = fus.gridmetrics(groundfile=groundfile,\n",
    "                                       heightbreak=1.37, # breast height, in meters\n",
    "                                       cellsize=10, # in units of lidar data\n",
    "                                       outputfile=outfile,\n",
    "                                       datafiles=infile,\n",
    "                                       strata=(0.15, 1.37, 5.0, 10.0, 20.0, 30.0),\n",
    "                                       intstrata=(0.15, 1.37, 5.0, 10.0, 20.0, 30.0),\n",
    "                                       las_class=(0,1,2,3,4,5),\n",
    "                                       topo=(10,latitude),\n",
    "                                       odir=odir) # will make sure output directory is created if doesn't already exist\n",
    "                \n",
    "            except PipelineError as e:\n",
    "                        log_error(tile_id, 'make_gridmetrics', e.message)\n",
    "    else: # output file already exists\n",
    "        pass\n",
    "                \n",
    "    return tile_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def make_gridsurfacestats(tile_id):\n",
    "    infile = os.path.join(interim, 'chm_tiles', tile_id + '.dtm')\n",
    "    odir = os.path.join(interim, 'gridsurface')\n",
    "    outfile = os.path.join(odir, tile_id + '.dtm')\n",
    "    \n",
    "    test_output = os.path.join(odir, tile_id + '_max_height' + '.dtm')\n",
    "    if not os.path.exists(test_output):\n",
    "        if not has_error(tile_id):\n",
    "            try:\n",
    "                proc = fus.gridsurfacestats(inputfile=infile,\n",
    "                                            outputfile=outfile,\n",
    "                                            # samplefactors describes number of cells to use in grid \n",
    "                                            samplefactor=20,  # this 0.5m CHM, will produce 10*10m grid\n",
    "                                            asc=True,\n",
    "                                            halfcell=True, # will align grid with gridmetrics\n",
    "                                            odir=odir) # will make sure output directory is created if doesn't already exist\n",
    "                \n",
    "            except PipelineError as e:\n",
    "                        log_error(tile_id, 'make_gridsurfacestats', e.message)\n",
    "    else: # output file already exists\n",
    "        pass\n",
    "                \n",
    "    return tile_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv2grid(tile_id, csvfile, col_num, col_name):\n",
    "    outfile = os.path.join(interim, 'gridmetrics', 'rasters', \n",
    "                           '{}_{}.asc'.format(tile_id, col_name))\n",
    "    odir = os.path.dirname(outfile)\n",
    "    \n",
    "    if not os.path.exists(outfile):\n",
    "        if not has_error(tile_id):\n",
    "            try:\n",
    "                proc = fus.csv2grid(inputfile=csvfile,\n",
    "                                    column=col_num,\n",
    "                                    outputfile=outfile,\n",
    "                                    odir=odir)\n",
    "                \n",
    "            except PipelineError as e:\n",
    "                        log_error(tile_id, 'csv2grid', e.message)\n",
    "    else: # output file already exists\n",
    "        pass\n",
    "                \n",
    "    return tile_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def batch_csv2grid(tile_id):\n",
    "    # read the csv containing strata data, identify the columns to extract\n",
    "    strata_data = os.path.join(interim, 'gridmetrics', tile_id + '_all_returns_strata_stats.csv')\n",
    "    \n",
    "    if not os.path.exists(strata_data):\n",
    "        log_error(tile_id, 'batch_csv2grid', '{} does not exist'.format(strata_data))\n",
    "        return tile_id\n",
    "    \n",
    "    with open(strata_data) as f:\n",
    "        header = f.readline()\n",
    "        cols = header.split(',')\n",
    "        strata_columns = [{'col_num': cols.index(col)+1, # FUSION wants indexing starting at 1\n",
    "                           'col_name': strata_cols_to_grid[col]}\n",
    "                          for col in cols if col in strata_cols_to_grid.keys()]\n",
    "\n",
    "    for col in strata_columns:\n",
    "        strata_proc = csv2grid(tile_id, strata_data, col['col_num'], col['col_name'])\n",
    "\n",
    "    \n",
    "    # read the csv containing topo data, identify the columns to extract\n",
    "    topo_data = os.path.join(interim, 'gridmetrics', tile_id + '_topo_metrics.csv')\n",
    "    with open(topo_data) as f:\n",
    "        header = f.readline()\n",
    "        cols = header.split(',')\n",
    "        topo_columns = [{'col_num': cols.index(col),\n",
    "                         'col_name': topo_cols_to_grid[col]}\n",
    "                        for col in cols if col in topo_cols_to_grid.keys()]\n",
    "\n",
    "    for col in topo_columns:\n",
    "        topo_proc = csv2grid(tile_id, topo_data, col['col_num'], col['col_name'])\n",
    "\n",
    "        \n",
    "    # read the csv containing elevation data, identify the columns to extract\n",
    "    elevation_data = os.path.join(interim, 'gridmetrics', tile_id + '_all_returns_elevation_stats.csv')    \n",
    "    with open(elevation_data) as f:\n",
    "        header = f.readline()\n",
    "        cols = header.split(',')\n",
    "        elevation_columns = [{'col_num': cols.index(col),\n",
    "                              'col_name': elevation_cols_to_grid[col]}\n",
    "                             for col in cols if col in elevation_cols_to_grid.keys()]\n",
    "\n",
    "    for col in elevation_columns:\n",
    "        elev_proc = csv2grid(tile_id, elevation_data, col['col_num'], col['col_name'])\n",
    "    \n",
    "    return tile_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def batch_asc2tif_gridmetrics(tile_id):\n",
    "    infiles = glob.glob(os.path.join(interim, 'gridmetrics', 'rasters', '{}*.asc'.format(tile_id)))\n",
    "    \n",
    "    for infile in infiles:\n",
    "        dirname, basename = os.path.split(infile)\n",
    "        outfilename = basename.split('.')[0] + '.tif'\n",
    "        outfile = os.path.join(dirname, outfilename)\n",
    "    \n",
    "        if not os.path.exists(outfile):\n",
    "            if not has_error(tile_id):\n",
    "                try:\n",
    "                    convert_project(infile, '.tif', 'EPSG:{}'.format(target_epsg))\n",
    "                except Exception as e:\n",
    "                    log_error(tile_id, 'batch_asc2tif_gridmetrics', e.message)\n",
    "        else: # output file already exists\n",
    "            pass\n",
    "    \n",
    "    return tile_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def batch_asc2tif_gridsurface(tile_id):\n",
    "    infiles = glob.glob(os.path.join(interim, 'gridsurface', '{}*.asc'.format(tile_id)))\n",
    "    \n",
    "    for infile in infiles:\n",
    "        dirname, basename = os.path.split(infile)\n",
    "        outfilename = basename.split('.')[0] + '.tif'\n",
    "        outfile = os.path.join(dirname, outfilename)\n",
    "    \n",
    "        if not os.path.exists(outfile):\n",
    "            if not has_error(tile_id):\n",
    "                try:\n",
    "                    convert_project(infile, '.tif', 'EPSG:{}'.format(target_epsg))\n",
    "                except Exception as e:\n",
    "                    log_error(tile_id, 'batch_asc2tif_gridsurface', e.message)\n",
    "        else: # output file already exists\n",
    "            pass\n",
    "    \n",
    "    return tile_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def remove_gridmetrics_buffer(tile_id, *args):\n",
    "    if type(tile_id) == list:\n",
    "        tile_id = tile_id[0]\n",
    "    infiles = glob.glob(os.path.join(interim, 'gridmetrics', 'rasters', '{}*.tif'.format(tile_id)))    \n",
    "    in_shp = os.path.join(interim, 'tile_boundaries', tile_id + '.shp')\n",
    "    odir = os.path.join(processed, 'rasters', 'gridmetrics_tiles')\n",
    "    \n",
    "    for infile in infiles:\n",
    "        basename = os.path.basename(infile)\n",
    "        outfile = os.path.join(odir, basename)\n",
    "    \n",
    "        if not os.path.exists(outfile):\n",
    "            if not has_error(tile_id):\n",
    "                try:\n",
    "                    clip_tile_from_shp(infile, \n",
    "                                       in_shp, \n",
    "                                       odir, \n",
    "                                       buffer=10)\n",
    "\n",
    "                except Exception as e:\n",
    "                    log_error(tile_id, 'remove_grid_metrics_buffer', e.message)\n",
    "        else: # output file already exists\n",
    "            pass\n",
    "    \n",
    "    return tile_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def remove_gridsurface_buffer(tile_id, *args):\n",
    "    if type(tile_id) == list:\n",
    "        tile_id = tile_id[0]\n",
    "    infiles = glob.glob(os.path.join(interim, 'gridsurface', '{}*.tif'.format(tile_id)))    \n",
    "    in_shp = os.path.join(interim, 'tile_boundaries', tile_id + '.shp')\n",
    "    odir = os.path.join(processed, 'rasters', 'gridmetrics_tiles')\n",
    "    \n",
    "    for infile in infiles:\n",
    "        basename = os.path.basename(infile)\n",
    "        outfile = os.path.join(odir, basename)\n",
    "    \n",
    "        if not os.path.exists(outfile):\n",
    "            if not has_error(tile_id):\n",
    "                try:\n",
    "                    clip_tile_from_shp(infile, \n",
    "                                       in_shp, \n",
    "                                       odir,\n",
    "                                       buffer=10)\n",
    "\n",
    "                except Exception as e:\n",
    "                    log_error(tile_id, 'remove_grid_surface_buffer', e.message)\n",
    "        else: # output file already exists\n",
    "            pass\n",
    "    \n",
    "    return tile_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def tile_done(tile_id, *args, **kwargs):\n",
    "    if type(tile_id) == list:\n",
    "        tile_id = tile_id[0]\n",
    "        \n",
    "    outfile = os.path.join(interim, 'finished_gridmetrics', tile_id + '.txt')\n",
    "    os.makedirs(os.path.dirname(outfile), exist_ok=True)\n",
    "    \n",
    "    with open(outfile, '+a') as f:\n",
    "        f.write('{}'.format(tile_id))\n",
    "    \n",
    "    return tile_id\n",
    "\n",
    "@dask.delayed\n",
    "def tiles_done(*args, **kwargs):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_ids = set(fname(tile) for tile in\n",
    "                         glob.glob(os.path.join(interim, 'retiled', '*.laz'))\n",
    "                        )\n",
    "\n",
    "failed_tiles = set(fname(tile) for tile in \n",
    "                   glob.glob(os.path.join(interim, 'failed', '*.txt'))\n",
    "                  )\n",
    "\n",
    "finished_tiles = set(fname(tile) for tile in \n",
    "                   glob.glob(os.path.join(interim, 'finished_gridmetrics', '*.txt'))\n",
    "                  )\n",
    "\n",
    "tiles_to_process = list(tile_ids - failed_tiles - finished_tiles)\n",
    "\n",
    "print('Found {:,d} tiles to process'.format(len(tiles_to_process)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_to_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk = {}\n",
    "for tile in tiles_to_process:\n",
    "#     dsk['make_gridsurfacestats-{}'.format(tile)]=(make_gridsurfacestats, tile)\n",
    "#     dsk['make_gridmetrics-{}'.format(tile)]=(make_gridmetrics, tile)\n",
    "    \n",
    "#     dsk['batch_asc2tif_gridsurface-{}'.format(tile)]=(batch_asc2tif_gridsurface, 'make_gridsurfacestats-{}'.format(tile))\n",
    "#     dsk['batch_csv2grid-{}'.format(tile)]=(batch_csv2grid, 'make_gridmetrics-{}'.format(tile))\n",
    "    dsk['batch_csv2grid-{}'.format(tile)]=(batch_csv2grid, tile)\n",
    "    dsk['batch_asc2tif_gridmetrics-{}'.format(tile)]=(batch_asc2tif_gridmetrics, 'batch_csv2grid-{}'.format(tile))\n",
    "    \n",
    "#     dsk['remove_gridsurface_buffer-{}'.format(tile)]=(remove_gridsurface_buffer, 'batch_asc2tif_gridsurface-{}'.format(tile))\n",
    "    dsk['remove_gridmetrics_buffer-{}'.format(tile)]=(remove_gridmetrics_buffer, 'batch_asc2tif_gridmetrics-{}'.format(tile))\n",
    "    \n",
    "    dsk['tile_done-{}'.format(tile)]=(tile_done, 'remove_gridmetrics_buffer-{}'.format(tile))\n",
    "#     dsk['tile_done-{}'.format(tile)]=(tile_done, ['remove_gridsurface_buffer-{}'.format(tile),\n",
    "#                                                   'remove_gridmetrics_buffer-{}'.format(tile)])\n",
    "    \n",
    "dsk['tiles_done'] = (tiles_done, ['tile_done-{}'.format(tile) for tile in tiles_to_process])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "example_tile_graph = c.get(dsk, 'tile_done-{}'.format(tiles_to_process[0]))\n",
    "example_tile_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_graph = c.get(dsk, 'tiles_done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_results = c.compute(tiles_graph) # this might take a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress(tiles_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiles_results.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = glob.glob(os.path.join(interim, 'failed', '*.txt'))\n",
    "finished = [os.path.basename(tile).split('.')[0] for tile in glob.glob(os.path.join(interim, 'finished_gridmetrics', '*.txt'))]\n",
    "\n",
    "summary = '''\n",
    "Processing Summary\n",
    "-------------------\n",
    "{:>5,d} tiles in acquisition\n",
    "{:>5,d} tiles previously finished in acquisition\n",
    "\n",
    "{:>5,d} tiles being processed in this run\n",
    "{:>5,d} tiles from this run finished\n",
    "\n",
    "{:>5,d} tiles failed\n",
    "'''.format(len(tile_ids), \n",
    "           len(finished_tiles),\n",
    "           len(tiles_to_process), \n",
    "           len(finished) - (len(tile_ids) - len(tiles_to_process)), \n",
    "           len(failed))\n",
    "\n",
    "total_percent_unfinished = int(70 * (1-len(finished)/len(tile_ids)))\n",
    "total_percent_finished = int(70 * len(finished)/len(tile_ids))\n",
    "total_percent_failed = int(70 * len(failed)/len(tile_ids))\n",
    "\n",
    "this_run_unfinished = int(70 - 70*(len(finished) - (len(tile_ids) - len(tiles_to_process))) / len(tiles_to_process))\n",
    "this_run_finished = int(70*(len(finished) - (len(tile_ids) - len(tiles_to_process))) / len(tiles_to_process))\n",
    "\n",
    "print(summary)\n",
    "print('|' + '=' * this_run_finished + \n",
    "      ' '* this_run_unfinished + \n",
    "      '!' * total_percent_failed + \n",
    "      '|  {:.1%} this run'.format(\n",
    "          (len(finished) - (len(tile_ids) - len(tiles_to_process))) / len(tiles_to_process)))\n",
    "print('|' + '=' * total_percent_finished + \n",
    "      ' ' * total_percent_unfinished + \n",
    "      '!' * total_percent_failed + \n",
    "      '|  {:.1%} total'.format(\n",
    "          len(finished)/len(tile_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in failed:\n",
    "    with open(filename) as f:\n",
    "        print([line for line in f.readlines() if line.rstrip() != ''])\n",
    "    print('----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c.close()\n",
    "# cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyFIRS]",
   "language": "python",
   "name": "conda-env-pyFIRS-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
