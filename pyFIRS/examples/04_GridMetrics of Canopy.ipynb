{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import subprocess\n",
    "import time\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import dask\n",
    "from dask.distributed import Client, progress, LocalCluster\n",
    "from pyFIRS.wrappers import lastools, fusion\n",
    "from pyFIRS.utils import convert_project, PipelineError, fname, inspect_failures, processing_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define where your working directory and the geographic coordinate system you're working in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the imported lidar data is currently stored\n",
    "WORKDIR = os.path.abspath('/storage/lidar/olympic-peninsula_2005/')\n",
    "\n",
    "# the coordinate reference system we'll be working with\n",
    "TARGET_EPSG = 6339  # utm 10N, NAD83_2011"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the lidar data\n",
    "\n",
    "Launch a parallel computing cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(scheduler_port=7001, diagnostics_port=7002)\n",
    "c = Client(cluster)\n",
    "num_cores = len(c.ncores())  # identify how many workers we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you should also be able to view an interactive dashboard on port 7002. If you're executing this on a remote server, you'll need to set up port forward so you can view the dashboard on your local machine's browser. Once you've done that, or if you're processing on your own machine, you can view the dashboard at [http://localhost:7002/status](http://localhost:7002/status)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "las = lastools.useLAStools('/storage/lidar/LAStools/bin')\n",
    "fus = fusion.useFUSION('/storage/lidar/FUSION/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data handling directories\n",
    "INTERIM = os.path.join(WORKDIR, 'interim')\n",
    "PROCESSED = os.path.join(WORKDIR, 'processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_error(tile_id, process, error_msg):\n",
    "    logfile = os.path.join(INTERIM, 'failed', tile_id + '.txt')\n",
    "    os.makedirs(os.path.dirname(logfile), exist_ok=True)\n",
    "\n",
    "    with open(logfile, '+w') as f:\n",
    "        f.write('{} | {}: {}'.format(tile_id, process, error_msg))\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def has_error(tile_id):\n",
    "    errors = glob.glob(os.path.join(INTERIM, 'failed', '*.txt'))\n",
    "    tiles_with_errors = [fname(error) for error in errors]\n",
    "    if tile_id in tiles_with_errors:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strata_cols_to_grid = {'Elev strata (below 0.15) return proportion':\n",
    "                       'strat0_return-proportion',\n",
    "                       'Elev strata (0.15 to 1.37) return proportion':\n",
    "                       'strat1_return-proportion',\n",
    "                       'Elev strata (5.00 to 10.00) return proportion':\n",
    "                       'strat2_return-proportion',\n",
    "                       'Elev strata (10.00 to 20.00) return proportion':\n",
    "                       'strat3_return-proportion',\n",
    "                       'Elev strata (20.00 to 30.00) return proportion':\n",
    "                       'strat4_return-proportion',\n",
    "                       'Elev strata (above 30.00) return proportion':\n",
    "                       'strat5_return-proportion',\n",
    "                       'Int strata (below 0.15) median':\n",
    "                       'strat0_intensity-median',\n",
    "                       'Int strata (0.15 to 1.37) median':\n",
    "                       'strat1_intensity-median',\n",
    "                       'Int strata (1.37 to 5.00) median':\n",
    "                       'strat2_intensity-median',\n",
    "                       'Int strata (5.00 to 10.00) median':\n",
    "                       'strat3_intensity-median',\n",
    "                       'Int strata (10.00 to 20.00) median':\n",
    "                       'strat4_intensity-median',\n",
    "                       'Int strata (above 30.00) median':\n",
    "                       'strat5_intensity-median'}\n",
    "\n",
    "elevation_cols_to_grid = {'Elev P05':'height_05-percentile',\n",
    "                          'Elev P25':'height_25-percentile',\n",
    "                          'Elev P50':'height_50-percentile',\n",
    "                          'Elev P75':'height_75-percentile',\n",
    "                          'Elev P95':'height_95_percentile',\n",
    "                          'Elev maximum':'height_max',\n",
    "                          'Percentage all returns above 1.37':'cover'}\n",
    "\n",
    "topo_cols_to_grid = {'Elevation':'elevation',\n",
    "                     'Slope (degrees)':'slope',\n",
    "                     'Aspect (degrees azimuth)':'aspect',\n",
    "                     'Profile curvature * 100':'profile_curvature',\n",
    "                     'Plan curvature * 100':'plan_curvature',\n",
    "                     'Solar Radiation Index':'solar_radiation_index',\n",
    "                     'Overall Curvature':'overall_curvature'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push our working directories and wrapper classes to the workers on the cluster as well\n",
    "c.scatter([INTERIM, PROCESSED, las, fus, \n",
    "           TARGET_EPSG, num_cores, has_error, log_error,\n",
    "           strata_cols_to_grid, topo_cols_to_grid, elevation_cols_to_grid], \n",
    "          broadcast=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create canopy-derived rasters\n",
    "Calculate forest canopy attributes using the FUSION `gridmetrics` and `gridsurfacestats` tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def make_gridmetrics(tile_id):\n",
    "    infile = os.path.join(PROCESSED, 'points', tile_id + '.laz')\n",
    "    groundfile = os.path.join(INTERIM, 'dtm_ground_tiles', tile_id + '.dtm')\n",
    "    ODIR = os.path.join(PROCESSED, 'rasters', 'gridmetrics_tiles')\n",
    "    outfile = os.path.join(ODIR, tile_id + '.csv')\n",
    "    \n",
    "    # get the latitude of the tile centroid\n",
    "    gdf = gpd.read_file(os.path.join(INTERIM, 'tile_boundaries', tile_id+'.shp'))\n",
    "    latlon = gdf.exterior.centroid.to_crs({'init':'EPSG:4326'})\n",
    "    latitude = latlon.geometry.y.values[0]\n",
    "    \n",
    "    # get the coordinates of the lower left corner of the tile\n",
    "    tile_parts = tile_id.split('_')\n",
    "    if len(tile_parts) == 2:\n",
    "        grid_x, grid_y = [int(coord) for coord in tile_parts]\n",
    "        tile_length = 1000 # assumed tile width if not explicit in tile_id\n",
    "    elif len(tile_parts) == 3:\n",
    "        grid_x, grid_y, tile_length = [int(coord) for coord in tile_parts]\n",
    "    \n",
    "    if not os.path.exists(outfile):\n",
    "        if not has_error(tile_id):\n",
    "            try:\n",
    "                proc = fus.gridmetrics(groundfile=groundfile,\n",
    "                                       heightbreak=1.37,  # breast height (m)\n",
    "                                       cellsize=10,\n",
    "                                       grid=(grid_x, grid_y, tile_length, tile_length),\n",
    "                                       buffer=30,\n",
    "                                       outlier=(-1, 110),\n",
    "                                       outputfile=outfile,\n",
    "                                       datafiles=infile,\n",
    "                                       strata=(0.15, 1.37, 5.0, 10.0, 20.0, 30.0),\n",
    "                                       intstrata=(0.15, 1.37, 5.0, 10.0, 20.0, 30.0),\n",
    "                                       las_class=(0, 1, 2, 3, 4, 5),\n",
    "                                       topo=(10, latitude),\n",
    "                                       odir=ODIR)\n",
    "                \n",
    "            except PipelineError as e:\n",
    "                        log_error(tile_id, 'make_gridmetrics', e.message)\n",
    "    else: # output file already exists\n",
    "        pass\n",
    "                \n",
    "    return tile_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def make_gridsurfacestats(tile_id):\n",
    "    infile = os.path.join(INTERIM, 'chm_tiles', tile_id + '.dtm')\n",
    "    ODIR = os.path.join(INTERIM, 'gridsurface')\n",
    "    outfile = os.path.join(ODIR, tile_id + '.dtm')\n",
    "    \n",
    "    tile_parts = tile_id.split('_')\n",
    "    if len(tile_parts) == 2:\n",
    "        grid_x, grid_y = [int(coord) for coord in tile_parts]\n",
    "        tile_length = 1000 # assumed tile width if not explicit in tile_id\n",
    "    elif len(tile_parts) == 3:\n",
    "        grid_x, grid_y, tile_length = [int(coord) for coord in tile_parts]\n",
    "    \n",
    "    test_output = os.path.join(ODIR, tile_id + '_max_height' + '.dtm')\n",
    "    if not os.path.exists(test_output):\n",
    "        if not has_error(tile_id):\n",
    "            try:\n",
    "                proc = fus.gridsurfacestats(\n",
    "                    inputfile=infile,\n",
    "                    outputfile=outfile,\n",
    "                    # samplefactor describes number of cells to use in grid\n",
    "                    samplefactor=20,  # 20*0.5m cells will produce 10*10m grid\n",
    "                    grid=(grid_x, grid_y, 1000, 1000),  # clips boundary\n",
    "                    asc=True,\n",
    "                    odir=ODIR)\n",
    "                \n",
    "            except PipelineError as e:\n",
    "                try:\n",
    "                    log_error(tile_id, 'make_gridsurfacestats', e.message)\n",
    "                except AttributeError:\n",
    "                    log_error(tile_id, 'make_gridsurfacestats', e)\n",
    "    else: # output file already exists\n",
    "        pass\n",
    "                \n",
    "    return tile_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert FUSION `gridmetrics` outputs from CSV to GeoTIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv2grid(tile_id, csvfile, col_num, col_name):\n",
    "    outfile = os.path.join(INTERIM, 'gridmetrics', 'rasters', \n",
    "                           '{}_{}.asc'.format(tile_id, col_name))\n",
    "    odir = os.path.dirname(outfile)\n",
    "    \n",
    "    if not os.path.exists(outfile):\n",
    "        if not has_error(tile_id):\n",
    "            try:\n",
    "                proc = fus.csv2grid(inputfile=csvfile,\n",
    "                                    column=col_num,\n",
    "                                    outputfile=outfile,\n",
    "                                    odir=odir)\n",
    "                \n",
    "            except PipelineError as e:\n",
    "                        log_error(tile_id, 'csv2grid', e.message)\n",
    "    else: # output file already exists\n",
    "        pass\n",
    "                \n",
    "    return tile_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def batch_csv2grid(tile_id):\n",
    "    GRIDMET_DIR = os.path.join(\n",
    "        PROCESSED, 'rasters', 'gridmetrics_tiles')\n",
    "    # read the csv containing strata data, identify the columns to extract\n",
    "    strata_data = os.path.join(\n",
    "        GRIDMET_DIR, tile_id + '_all_returns_strata_stats.csv')\n",
    "    \n",
    "    if not os.path.exists(strata_data):\n",
    "        log_error(tile_id, \n",
    "                  'batch_csv2grid', \n",
    "                  '{} does not exist'.format(strata_data))\n",
    "        return tile_id\n",
    "    \n",
    "    with open(strata_data) as f:\n",
    "        header = f.readline().strip()\n",
    "        cols = header.split(',')\n",
    "        strata_columns = [{'col_num': cols.index(col) + 1,  # FUSION indexing starts at 1\n",
    "                           'col_name': strata_cols_to_grid[col]}\n",
    "                          for col in cols if col in strata_cols_to_grid.keys()]\n",
    "\n",
    "    for col in strata_columns:\n",
    "        strata_proc = csv2grid(tile_id,\n",
    "                               strata_data,\n",
    "                               col['col_num'],\n",
    "                               col['col_name'])\n",
    "\n",
    "    \n",
    "    # read the csv containing topo data, identify the columns to extract\n",
    "    topo_data = os.path.join(\n",
    "        GRIDMET_DIR, tile_id + '_topo_metrics.csv')\n",
    "    with open(topo_data) as f:\n",
    "        header = f.readline().strip()\n",
    "        cols = header.split(',')\n",
    "        topo_columns = [{'col_num': cols.index(col) + 1,\n",
    "                         'col_name': topo_cols_to_grid[col]}\n",
    "                        for col in cols if col in topo_cols_to_grid.keys()]\n",
    "\n",
    "    for col in topo_columns:\n",
    "        topo_proc = csv2grid(tile_id,\n",
    "                             topo_data,\n",
    "                             col['col_num'],\n",
    "                             col['col_name'])\n",
    "\n",
    "        \n",
    "    # read the csv containing elevation data, identify the columns to extract\n",
    "    elevation_data = os.path.join(\n",
    "        GRIDMET_DIR, tile_id + '_all_returns_elevation_stats.csv')    \n",
    "    with open(elevation_data) as f:\n",
    "        header = f.readline().strip()\n",
    "        cols = header.split(',')\n",
    "        elevation_columns = [{'col_num': cols.index(col) + 1,\n",
    "                              'col_name': elevation_cols_to_grid[col]}\n",
    "                             for col in cols if col in elevation_cols_to_grid.keys()]\n",
    "\n",
    "    for col in elevation_columns:\n",
    "        elev_proc = csv2grid(tile_id,\n",
    "                             elevation_data,\n",
    "                             col['col_num'],\n",
    "                             col['col_name'])\n",
    "    \n",
    "    return tile_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def batch_asc2tif_gridmetrics(tile_id):\n",
    "    infiles = glob.glob(\n",
    "        os.path.join(INTERIM, 'gridmetrics', \n",
    "                     'rasters', '{}*.asc'.format(tile_id)))\n",
    "    ODIR = os.path.join(\n",
    "        PROCESSED, 'rasters', 'gridmetrics_tiles')\n",
    "    os.makedirs(ODIR, exist_ok=True)\n",
    "    \n",
    "    for infile in infiles:\n",
    "        filename = fname(infile)\n",
    "        outfile = os.path.join(ODIR, filename + '.tif')\n",
    "    \n",
    "        if not os.path.exists(outfile):\n",
    "            if not has_error(tile_id):\n",
    "                try:\n",
    "                    convert_project(infile,\n",
    "                                    outfile,\n",
    "                                    'EPSG:{}'.format(TARGET_EPSG))\n",
    "                except Exception as e:\n",
    "                    log_error(tile_id,\n",
    "                              'batch_asc2tif_gridmetrics',\n",
    "                              e.message)\n",
    "        else: # output file already exists\n",
    "            pass\n",
    "    \n",
    "    return tile_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert FUSION `gridsurfacestats` outputs from ASC to GeoTIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def batch_asc2tif_gridsurface(tile_id):\n",
    "    infiles = glob.glob(\n",
    "        os.path.join(INTERIM, 'gridsurface', '{}*.asc'.format(tile_id)))\n",
    "    ODIR = os.path.join(\n",
    "        PROCESSED, 'rasters', 'gridsurface_tiles')\n",
    "    os.makedirs(ODIR, exist_ok=True)\n",
    "    \n",
    "    for infile in infiles:\n",
    "        filename = fname(infile)\n",
    "        outfile = os.path.join(ODIR, filename + '.tif')\n",
    "    \n",
    "        if not os.path.exists(outfile):\n",
    "            if not has_error(tile_id):\n",
    "                try:\n",
    "                    convert_project(infile,\n",
    "                                    outfile,\n",
    "                                    'EPSG:{}'.format(TARGET_EPSG))\n",
    "                except Exception as e:\n",
    "                    log_error(tile_id,\n",
    "                              'batch_asc2tif_gridsurface',\n",
    "                              e.message)\n",
    "        else: # output file already exists\n",
    "            pass\n",
    "    \n",
    "    return tile_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def tile_done(tile_id, *args, **kwargs):\n",
    "    if type(tile_id) == list:\n",
    "        tile_id = tile_id[0]\n",
    "        \n",
    "    outfile = os.path.join(\n",
    "        INTERIM, 'finished_gridmetrics', tile_id + '.txt')\n",
    "    os.makedirs(os.path.dirname(outfile), exist_ok=True)\n",
    "    \n",
    "    if not has_error(tile_id):\n",
    "        with open(outfile, '+a') as f:\n",
    "            f.write('{}'.format(tile_id))\n",
    "    \n",
    "    return tile_id\n",
    "\n",
    "@dask.delayed\n",
    "def tiles_done(*args, **kwargs):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify the tiles to be processed\n",
    "Account for previously-executed pipelines that have already processed some of the tiles in this acquisition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_ids = set(fname(tile) for tile in\n",
    "               glob.glob(\n",
    "                   os.path.join(PROCESSED, 'points', '*.laz')))\n",
    "\n",
    "failed_tiles = set(fname(tile) for tile in \n",
    "                   glob.glob(\n",
    "                       os.path.join(INTERIM, 'failed', '*.txt')))\n",
    "\n",
    "finished_tiles = set(fname(tile) for tile in\n",
    "                     glob.glob(\n",
    "                         os.path.join(INTERIM,\n",
    "                                      'finished_gridmetrics',\n",
    "                                      '*.txt')))\n",
    "\n",
    "tiles_to_process = list(tile_ids - failed_tiles - finished_tiles)\n",
    "\n",
    "print('Found {:,d} tiles to process'.format(len(tiles_to_process)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk = {}\n",
    "for tile in tiles_to_process:\n",
    "    dsk['make_gridsurfacestats-{}'.format(tile)] = (\n",
    "        make_gridsurfacestats,\n",
    "        tile)\n",
    "    dsk['make_gridmetrics-{}'.format(tile)] = (\n",
    "        make_gridmetrics,\n",
    "        tile)\n",
    "\n",
    "    dsk['batch_asc2tif_gridsurface-{}'.format(tile)] = (\n",
    "        batch_asc2tif_gridsurface,\n",
    "        'make_gridsurfacestats-{}'.format(tile))\n",
    "    dsk['batch_csv2grid-{}'.format(tile)] = (\n",
    "        batch_csv2grid,\n",
    "        'make_gridmetrics-{}'.format(tile))\n",
    "    dsk['batch_asc2tif_gridmetrics-{}'.format(tile)] = (\n",
    "        batch_asc2tif_gridmetrics,\n",
    "        'batch_csv2grid-{}'.format(tile))\n",
    "\n",
    "    dsk['tile_done-{}'.format(tile)] = (\n",
    "        tile_done,\n",
    "        ['batch_asc2tif_gridsurface-{}'.format(tile),\n",
    "         'batch_asc2tif_gridmetrics-{}'.format(tile)])\n",
    "\n",
    "dsk['tiles_done'] = (\n",
    "    tiles_done, \n",
    "    ['tile_done-{}'.format(tile) for tile in tiles_to_process])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "example_tile_graph = c.get(dsk,\n",
    "                           'tile_done-{}'.format(tiles_to_process[0]))\n",
    "example_tile_graph.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dask to schedule the aynchronous parallel execution of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_graph = c.get(dsk, 'tiles_done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_results = c.persist(tiles_graph) # this might take a while...\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor the progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress(tiles_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c.cancel(tiles_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiles_results.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_summary(tile_ids, finished_tiles, \n",
    "                   tiles_to_process, \n",
    "                   os.path.join(INTERIM, 'finished_gridmetrics'), \n",
    "                   os.path.join(INTERIM, 'failed'),\n",
    "                   start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_failures(os.path.join(INTERIM, 'failed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c.close()\n",
    "# cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyFIRS] *",
   "language": "python",
   "name": "conda-env-pyFIRS-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
