{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import pdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = '/storage/lidar/odf_northwest_2015'\n",
    "raw = os.path.join(workdir, 'raw')\n",
    "interim = os.path.join(workdir, 'interim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retile the data to add buffers for avoiding edge effects during processing.\n",
    "\n",
    "In practice, executing the `lastile` command on individual tiles in parallel is likely to corrupt your output files. I suspect this is because the dynamic re-tiling of input files means that many output tiles are likely to require inputs from multiple input files, and that parallel processing outside of LAStools may result in collisions writing data from multiple inputs to these output tiles. So, for this case, we'll let `lastile` handle the parallelism under the hood. We won't have a progress bar, but this shouldn't take more than 5-10 minutes per ~100 tiles (with vendor tile size ~1000x1000m with 4-8 pts/m2).\n",
    "\n",
    "**THERE ARE ARGUMENTS IN THE FOLLOWING COMMAND THAT DEPEND UPON THE UNITS OF THE DATA.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# tile_proc = las.lastile(i=os.path.join(raw, '*.laz'),\n",
    "#                         tile_size=1000, # in units of lidar data\n",
    "#                         buffer=25, # assumes units are in meters\n",
    "#                         flag_as_withheld=True, # flag qbuffer points as \"withheld\", enables handling with other LAStools\n",
    "#                         extra_pass=True, # if outputting to LAZ format, can help avoid memory limits\n",
    "#                         full_bb=True,\n",
    "#                         olaz=True,\n",
    "#                         odir='/storage/lidar/odf_northwest_2015/interim/retiled',\n",
    "#                         cores=num_cores);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "src_laz = '{}/*.laz'.format(raw)\n",
    "out_idx = '{}/index.sqlite'.format(raw)\n",
    "subprocess.run(['pdal', 'tindex', src_laz, out_idx, '-f', '\"SQLite\"', '--lyr_name', '\"pdal\"'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json = \"\"\"\n",
    "{\n",
    "  \"pipeline\": [\n",
    "    {\n",
    "      \"type\":\"readers.tindex\",\n",
    "      \"filename\":\"{}/index.sqlite\",\n",
    "    },\n",
    "    {\n",
    "      \"type\":\"filters.splitter\",\n",
    "      \"length\":\"1000\",\n",
    "      \"buffer\":\"25\"\n",
    "    },\n",
    "    {\n",
    "      \"type\":\"filters.sample\",\n",
    "      \"radius\":\"0.01\"\n",
    "    },\n",
    "    {\n",
    "      \"type\":\"writers.las\",\n",
    "      \"filename\":\"{}/#.laz\",\n",
    "      \"compression\":\"laszip\"\n",
    "    }\n",
    "  ]\n",
    "}\"\"\".format(raw, os.path.join(interim, 'retiled'))\n",
    "\n",
    "pipeline = pdal.Pipeline(json)\n",
    "pipeline.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "count = pipeline.execute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
